{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stMjFoLNMohS"
      },
      "source": [
        "# Project 4: Model Performance and Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4qlHyzCMohV"
      },
      "source": [
        "## Part B: Sklearn and Natural Language Processing\n",
        "In this part, you will apply sklearn and related NLP libraries to perform data analysis on the [IMDB movie review dataset](https://ai.stanford.edu/~amaas/data/sentiment/). Before you begin, check that your installed `scikit-learn` version is as specified in `requirements.txt`; otherwise you may not pass the local tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aCZJbXpzMohW"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.sparse as sp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pjeVxgNMohX"
      },
      "source": [
        "We begin by loading a subset of the dataset, which contains 5000 movie reviews and their associated sentiment labels (i.e., whether a review is considered positive or negative)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "er1uSmLTMohX"
      },
      "outputs": [],
      "source": [
        "df_reviews = pd.read_csv(\"imdb_reviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [
          "excluded_from_script"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mtEZf1ZRMohX",
        "outputId": "2eec5a53-05dd-47ad-d941-c792ef5b69a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  \\\n",
              "0  Taran Adarsh a reputed critic praised such a d...   \n",
              "1  Worth the entertainment value of a rental, esp...   \n",
              "2  I liked Antz, but loved \"A Bug's Life\". The an...   \n",
              "3  This reboot is like a processed McDonald's mea...   \n",
              "4  The working title was: \"Don't Spank Baby\". <br...   \n",
              "\n",
              "                                    processed_review sentiment  \n",
              "0  taran adarsh repute critic praise dubba movie ...  negative  \n",
              "1  worth entertainment value rental especially li...  negative  \n",
              "2  like antz love bug life animation put paid def...  positive  \n",
              "3  reboot like process mcdonald meal compare ang ...  negative  \n",
              "4  work title spank baby wayne crawford go become...  positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0784062e-7aaf-4dfa-aaaa-15a35d171a08\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>processed_review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Taran Adarsh a reputed critic praised such a d...</td>\n",
              "      <td>taran adarsh repute critic praise dubba movie ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Worth the entertainment value of a rental, esp...</td>\n",
              "      <td>worth entertainment value rental especially li...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I liked Antz, but loved \"A Bug's Life\". The an...</td>\n",
              "      <td>like antz love bug life animation put paid def...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This reboot is like a processed McDonald's mea...</td>\n",
              "      <td>reboot like process mcdonald meal compare ang ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The working title was: \"Don't Spank Baby\". &lt;br...</td>\n",
              "      <td>work title spank baby wayne crawford go become...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0784062e-7aaf-4dfa-aaaa-15a35d171a08')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0784062e-7aaf-4dfa-aaaa-15a35d171a08 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0784062e-7aaf-4dfa-aaaa-15a35d171a08');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-706a4154-ab4e-4696-a3a2-c59baa2154c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-706a4154-ab4e-4696-a3a2-c59baa2154c8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-706a4154-ab4e-4696-a3a2-c59baa2154c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_reviews",
              "summary": "{\n  \"name\": \"df_reviews\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4995,\n        \"samples\": [\n          \"OK me and a friend rented this a few days ago because we like to keep track of b-movies since we do them ourselves. Anyway, the cover contained blood and weird looking naked girls with fangs and stuff... and Tom Savini! There is just no way this movie can fail! Right? wrong!! It just seems like such a waste! There was really no story, the dialog was terrible (is anyone there? x 1000!!!), the characters were.. well, they really lacked any kind of personality... The effects were terrible.. and whats up with these long artsy shots of scared people running around doing nothing.. with extreme closeups of eyes and stuff? We were sitting the whole movie waiting for something... anything to happen... but no... \\\"oh, here comes the nymphs! great! oh.. they're kissing... again... and now for the violence! OK... nothing really happens... again... oh, now they run around... and the closeups of eyes... again... oh, heres Tom Savini! Oh... he died... right... OK, maybe now something cool or even interesting will happen.. no.. oh! Cool! a severed head! the end... oh crap..\\\" And finally, since i'm so full of myself.. i'll tell you this! Give me a van, six actors, a weird looking house, Tom Savini, a couple of naked girls with fangs and buckets of blood and i could make the coolest movie you've ever seen... I've made movies with zero budget in two days that has better effects, better acting and a better script than this... what is this Johannes guy doing?? Making cool movies is easy!It could have been so great... I'm really upset!!\",\n          \"Gary Cooper is a cool headed guy. Always liked his easy going level headed characters. As some others have commented, there are some oddities in the script, such as a US Marshall who got his job and can't even hit a barn with a pistol. A rancher with about thirty hands but can't seem to keep his cattle from being run off.<br /><br />But there is plenty of the quick thinking, straight shooting Cooper to keep you entertained.<br /><br />This movie was made in 1950. People in their 20's and 30's have trouble understanding those movies were made for entertainment not Oscars. <br /><br />To expect Oscar material does this film injustice. It is about the good guys finding a way to round up the bad guys.<br /><br />So rent, borrow, or buy this movie, pop some corn and enjoy the Coop one more time.\",\n          \"Up until the last 20 minutes, I was thinking that this is possibly Jackie Chan's worst movie (excluding his pre-1978 work, which I am not familiar with). The final fight sequence changed all that: it is long and good and intense - indeed, one of the highlights of Chan's career. But to get to it, you have to sit through a lot of \\\"comedy\\\" that might amuse five-year-olds (oh, look! someone threw a tomato at that guy's face) and endless \\\"football\\\" scenes. Not to mention the dubbing (which includes the line \\\"How can I turn it off? It's not a tap\\\" - watch to find out what it refers to). \\\"Dragon Lord\\\" is worth renting for the final fight alone, but the rest of the movie is only for Jackie collectors, and even then only for those who've already seen at least 15 of his other movies. (**)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed_review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4995,\n        \"samples\": [\n          \"ok friend rent day ago like keep track movie since anyway cover contain blood weird look naked girl fang stuff tom savini way movie fail right wrong seem like waste really story dialog terrible anyone 1000 character well really lack kind personality effect terrible whats long artsy shot scar people run around nothing extreme closeup eye stuff sit whole movie wait something anything happen oh come nymph great oh kiss violence ok nothing really happens oh run around closeup eye oh tom savini oh die right ok maybe something cool even interest happen oh cool sever head end oh crap finally since full tell give van six actor weird look house tom savini couple naked girl fang bucket blood could make coolest movie ever see make movie zero budget two day well effect well act well script johannes guy make cool movie easy could great really upset\",\n          \"gary cooper cool head guy always like easy go level head character others comment oddity script marshall get job ca even hit barn pistol rancher thirty hand ca seem keep cattle run plenty quick think straight shoot cooper keep entertain movie make 1950 people 20 30 trouble understand movie make entertainment oscar expect oscar material film injustice good guy find way round bad guy rent borrow buy movie pop corn enjoy coop one time\",\n          \"last 20 minute think possibly jackie chan bad movie exclude pre 1978 work familiar final fight sequence change long good intense indeed one highlight chan career get sit lot comedy might amuse five year old oh look someone threw tomato guy face endless football scene mention dub include line turn tap watch find refers dragon lord worth rent final fight alone rest movie jackie collector even already see least 15 movie\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# this cell has been tagged with excluded_from_script\n",
        "# it will be ignored by the autograder\n",
        "df_reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRvlr9w6MohX"
      },
      "source": [
        "The `review` column contains raw review texts from the original dataset. However, it's always a good idea to process and clean text data before performing analysis. As you have performed this task in Project 3, we will provide the processed reviews for you in this case. The column `processed_review` was constructed by processing and tokenizing the raw reviews, using the `preprocess_text` function from Project 3, and then joining the review tokens by a single space. From this point, you only need to focus on the `processed_review` and `sentiment` columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl_h3ZRQMohY"
      },
      "source": [
        "Next, let's look at the distribution of class labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [
          "excluded_from_script"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "ByypDY42MohY",
        "outputId": "f690e2a8-e83a-4f02-af80-caf56b51a487"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentiment\n",
              "negative    2500\n",
              "positive    2500\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>2500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# this cell has been tagged with excluded_from_script\n",
        "# it will be ignored by the autograder\n",
        "display(df_reviews['sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEKXBUU1MohY"
      },
      "source": [
        "We see that there are 2500 positive reviews and 2500 negative reviews. In other words, our dataset is [perfectly balanced](https://i.imgflip.com/303krn.jpg)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ600bPWMohY"
      },
      "source": [
        "### Question 11: Count Vectorizer\n",
        "\n",
        "The first feature construction task we will perform is building a term-frequency matrix. Implement the function `count_vectorizer` that uses sklearn's `CountVectorizer` API to construct the term-frequency training matrix and testing matrix, along with the feature names (i.e., the list of words corresponding to the columns in the matrices).\n",
        "\n",
        "One point to keep in mind is that `CountVectorizer` will, by default, do its own preprocessing and tokenization (see the [documentation](https://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes) for more details). As these steps have already performed, we will need to overwrite sklearn's default behaviors by specifying the following parameters:\n",
        "* `analyzer` and `tokenizer` should be `str.split`.\n",
        "* `preprocessor` should be a function that simply returns the input. We have built this function, called `dummy_fun`, for you.\n",
        "\n",
        "\n",
        " **Notes**:\n",
        " * Recall from the data normalization function in Part A that, with any feature construction or transformation task, we will only perform fitting on the train data, and then transform both train and test data. In other words, no fitting should be done on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GiG_nR-qMohY"
      },
      "outputs": [],
      "source": [
        "def dummy_fun(x):\n",
        "    return x\n",
        "\n",
        "def count_vectorizer(reviews_train, reviews_test = None):\n",
        "    \"\"\"\n",
        "    Compute the term-frequency matrices for train_data and test_data using CountVectorizer.\n",
        "\n",
        "    args:\n",
        "        reviews_train (pd.Series[str]) : a Series of processed reviews for training\n",
        "\n",
        "    kwargs:\n",
        "        reviews_test (pd.Series[str]) : a Series of processed reviews for testing\n",
        "\n",
        "    return:\n",
        "        Tuple(tf_train, tf_test, features):\n",
        "            tf_train (scipy.sparse.csr_matrix) : TF matrix for training\n",
        "            tf_test (scipy.sparse.csr_matrix) : TF matrix for testing,\n",
        "                or None if reviews_test is None\n",
        "            features (List[str]) : the list of words corresponding to the columns in the TF matrices\n",
        "    \"\"\"\n",
        "    vectorizer = CountVectorizer(\n",
        "        analyzer = \"word\",\n",
        "        tokenizer = str.split,\n",
        "        preprocessor = dummy_fun,\n",
        "        token_pattern=None\n",
        "    )\n",
        "\n",
        "    tr_train = vectorizer.fit_transform(reviews_train)\n",
        "    features = list(vectorizer.get_feature_names_out())\n",
        "\n",
        "    tf_test = vectorizer.transform(reviews_test) if reviews_test is not None else None\n",
        "\n",
        "    return tr_train, tf_test, features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [
          "excluded_from_script"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1HccQ6sMohY",
        "outputId": "fc9d93a2-12b6-415e-e923-7f342cddde6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ],
      "source": [
        "def test_count_vectorizer():\n",
        "    reviews_train, reviews_test = train_test_split(df_reviews[\"processed_review\"], random_state = 0)\n",
        "    count_vec_train, count_vec_test, features = count_vectorizer(reviews_train, reviews_test)\n",
        "    assert count_vec_train.shape == (3750, 27242)\n",
        "    assert count_vec_test.shape == (1250, 27242)\n",
        "    assert np.allclose(\n",
        "        count_vec_train.sum(axis = 1)[:10].ravel().tolist()[0],\n",
        "        [70, 65, 168, 77, 139, 132, 28, 139, 453, 89]\n",
        "    )\n",
        "    assert np.allclose(\n",
        "        count_vec_test.sum(axis = 1)[:10].ravel().tolist()[0],\n",
        "        [168, 60, 59, 144, 494, 135, 69, 119, 76, 68]\n",
        "    )\n",
        "    assert features[:10] == ['00', '000', '00015', '007', '00pm', '00s', '01', '01pm', '02', '029']\n",
        "    assert features[-10:] == ['zucco', 'zucker', 'zukovic', 'zula', 'zuleika', 'zumhofe', 'zurer', 'zvezda', 'zwick', 'zylberstein']\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "test_count_vectorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CIHz4rXMohZ"
      },
      "source": [
        "### Question 12: TF-IDF Vectorizer\n",
        "\n",
        "Now let's use the TF-IDF feature construction method. Implement the function `tfidf_vectorizer` that uses sklearn's `TfidfVectorizer` API to construct the TF-IDF training matrix and testing matrices, along with the feature names (i.e., the list of words corresponding to the columns in the matrices). Use the same parameter values for `analyzer`, `tokenizer` and `preprocessor` as you did in the previous question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBn6bLzKMohZ"
      },
      "outputs": [],
      "source": [
        "def tfidf_vectorizer(reviews_train, reviews_test = None):\n",
        "    \"\"\"\n",
        "    Compute the TF-IDF matrices for train_data and test_data using TfidfVectorizer.\n",
        "\n",
        "    args:\n",
        "        reviews_train (pd.Series[str]) : a Series of processed reviews for training\n",
        "\n",
        "    kwargs:\n",
        "        reviews_test (pd.Series[str]) : a Series of processed reviews for testing\n",
        "\n",
        "    return:\n",
        "        Tuple(tf_train, tf_test, features):\n",
        "            tf_train (scipy.sparse.csr_matrix) : TF-IDF matrix for training\n",
        "            tf_test (scipy.sparse.csr_matrix) : TF-IDF matrix for testing,\n",
        "                or None if reviews_test is None\n",
        "            features (List[str]) : the list of words corresponding to the columns in the TF-IDF matrices\n",
        "    \"\"\"\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        analyzer = \"word\",\n",
        "        tokenizer = str.split,\n",
        "        preprocessor = dummy_fun,\n",
        "        token_pattern=None\n",
        "    )\n",
        "\n",
        "    tr_train = vectorizer.fit_transform(reviews_train)\n",
        "    features = list(vectorizer.get_feature_names_out())\n",
        "\n",
        "    tf_test = vectorizer.transform(reviews_test) if reviews_test is not None else None\n",
        "\n",
        "    return tr_train, tf_test, features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "excluded_from_script"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYqzUhVJMohZ",
        "outputId": "c37bdb29-d592-4593-fe0b-16973bd434fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ],
      "source": [
        "def test_tfidf_vectorizer():\n",
        "    reviews_train, reviews_test = train_test_split(df_reviews[\"processed_review\"], random_state = 0)\n",
        "    tfidf_vec_trains, tfidf_vec_test, features = tfidf_vectorizer(reviews_train, reviews_test)\n",
        "    assert tfidf_vec_trains.shape == (3750, 27242)\n",
        "    assert tfidf_vec_test.shape == (1250, 27242)\n",
        "    assert np.allclose(\n",
        "        tfidf_vec_trains.sum(axis = 1)[:10].ravel().tolist()[0],\n",
        "        [7.03658925089979, 7.417196035144321, 11.492434722367015, 6.965673648338525, 9.428219597939362, 9.425632229448961, 3.9722806270035345, 9.635230284023372, 11.779155501275017, 7.44670396016231]\n",
        "    )\n",
        "    assert np.allclose(\n",
        "        tfidf_vec_test.sum(axis = 1)[:10].ravel().tolist()[0],\n",
        "        [7.2233277330801196, 4.869804242110142, 6.249091468966529, 9.689812079503804, 11.89432945296538, 9.115185225757216, 6.798492438570971, 8.57464867777901, 7.954528809138947, 6.81383392701789]\n",
        "    )\n",
        "    assert features[:10] == ['00', '000', '00015', '007', '00pm', '00s', '01', '01pm', '02', '029']\n",
        "    assert features[-10:] == ['zucco', 'zucker', 'zukovic', 'zula', 'zuleika', 'zumhofe', 'zurer', 'zvezda', 'zwick', 'zylberstein']\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "test_tfidf_vectorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QstPNrwJMohZ"
      },
      "source": [
        "### Question 13: Predicting review sentiment\n",
        "Let's now see which feature construction method -- TF or TF-IDF -- is better for predicting review sentiments in our dataset. Our choice of learning algorithm here will be a support vector machine with Gaussian kernel (this means that it uses a different hypothesis function that can also account for non-linearly separable data). You can apply this learning algorithm by creating an instance of sklearn's [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) class, with `kernel = \"rbf\"` and `C = 10`.\n",
        "\n",
        "Implement the function `predict_sentiment` that takes as input the `reviews` and `sentiment` columns of our IMDB dataset and performs the following tasks:\n",
        "1. Convert the `sentiment` column to a vector `y` of 1s and -1s: `positive` corresponds to 1 and `negative` to -1.\n",
        "1. Perform a [stratified k-fold split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) of the review and sentiment vectors, based on the provided `k`. Also set `shuffle` to `True` and `random_state` to the provided `seed`.\n",
        "1. For $f$ from $1 \\to k$:\n",
        "     * Let fold $f$ be the test set, and the remaining $k-1$ folds be the training set.\n",
        "     * Convert the training and testing reviews to feature matrices `X_train` and `X_test`, using either TF or TF-IDF. Which method to use is based on the function parameter `method`.\n",
        "     * Train the SVM model on `X_train, y_train` and evaluate its accuracy $a_f$ on `X_test, y_test`.\n",
        "1. Return $a_1, a_2, \\ldots, a_k$.\n",
        "\n",
        "**Notes**:\n",
        "* As a reminder, accuracy is defined as\n",
        "$$\\text{Acc} = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{1}(y^{(i)} = \\hat y^{(i)}).$$\n",
        "You can also use the `score` function from `SVC` to quickly compute accuracy on test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7V7QDv9MohZ"
      },
      "outputs": [],
      "source": [
        "def predict_review_sentiment(reviews, sentiments, method, k, seed = 0):\n",
        "    \"\"\"\n",
        "    Compute the cross-validated accuracy of SVM with either TF or TF-IDF features\n",
        "    in predicting review sentiment.\n",
        "\n",
        "    args:\n",
        "        reviews (pd.Series[str]) : a Series of all processed movie reviews\n",
        "        sentiments (pd.Series[str]) : a Series of movie review sentiments,\n",
        "            containing either \"positive\" or \"negative\"\n",
        "        method (str) : a string which is either \"TF\" or \"TF-IDF\",\n",
        "            specifying which feature construction method to use\n",
        "        k (int) : the number of folds in stratified k-fold split\n",
        "\n",
        "    kwargs:\n",
        "        seed (int) : the random generator seed for kfold split\n",
        "\n",
        "    return:\n",
        "        List[float] : a list of k accuracy values from evaluating a trained SVM model\n",
        "            on each of the k folds, using the remaining folds as training data\n",
        "    \"\"\"\n",
        "    y = np.where(sentiments == \"positive\", 1, -1)\n",
        "    skf = StratifiedKFold(n_splits = k, shuffle = True, random_state = seed)\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    for train_index, test_index in skf.split(reviews, y):\n",
        "      reviews_train, reviews_test = reviews[train_index], reviews[test_index]\n",
        "      y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "      if method == \"TF\":\n",
        "        X_train, X_test, _ = count_vectorizer(reviews_train, reviews_test)\n",
        "      elif method == \"TF-IDF\":\n",
        "        X_train, X_test, _ = tfidf_vectorizer(reviews_train, reviews_test)\n",
        "      else:\n",
        "        raise ValueError(\"method must be either 'TF' or 'TF-IDF'\")\n",
        "\n",
        "      svm = SVC(kernel = \"rbf\", C = 10)\n",
        "      svm.fit(X_train, y_train)\n",
        "\n",
        "      accuracies.append(svm.score(X_test, y_test))\n",
        "\n",
        "    return accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "excluded_from_script"
        ],
        "id": "Z-H12G_-MohZ"
      },
      "outputs": [],
      "source": [
        "def test_predict_review_sentiment():\n",
        "    # prediction based on TF\n",
        "    count_vec_accs = predict_review_sentiment(df_reviews[\"processed_review\"], df_reviews[\"sentiment\"], \"TF\", 10)\n",
        "    assert count_vec_accs == [0.878, 0.836, 0.854, 0.824, 0.826, 0.824, 0.824, 0.85, 0.844, 0.83]\n",
        "\n",
        "    # prediction based on TF-IDF\n",
        "    tf_idf_accs = predict_review_sentiment(df_reviews[\"processed_review\"], df_reviews[\"sentiment\"], \"TF-IDF\", 10)\n",
        "    assert tf_idf_accs == [0.88, 0.862, 0.85, 0.868, 0.854, 0.846, 0.864, 0.874, 0.874, 0.846]\n",
        "    print(\"All tests passed!\")\n",
        "    print(\"Cross-validated accuracy of SVM with TF matrices\", np.mean(count_vec_accs))\n",
        "    print(\"Cross-validated accuracy of SVM with TF-IDF matrices\", np.mean(tf_idf_accs))\n",
        "\n",
        "test_predict_review_sentiment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE16g0PFMohZ"
      },
      "source": [
        "We see that using TF-IDF features yields better cross-validated accuracy than using TF features (when the learning algorithm is SVM with RBF kernel and $C = 10$), although the difference in this case is not large."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxybkywZMohZ"
      },
      "source": [
        "### Question 14: Topic modeling and word distribution\n",
        "Let's now try to understand the review texts a bit more. We can treat all the reviews as a corpus and perform Latent Dirichlet Allocation to extract the corpus topics. We can also see which words are most frequent in a given topic. Implement the function `top_words_by_topic` that takes as input the `processed_reviews` column in our IMDB dataset and performs the following tasks:\n",
        "\n",
        "1. Build a term-frequency matrix out of this column. Remember to use the same `CountVectorizer` parameters as in Q11.\n",
        "1. Input this matrix to sklearn's `LatentDirichletAllocation`. The number of topics and random generator seed are provided as function parameters. You should specify `learning_method` as `\"online\"`.\n",
        "1. In the resulting word-topic matrix, identify the most frequent `n_top_words` in each topic. These most frequent words should be sorted from lower to higher frequency."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def top_words_by_topic(reviews, n_topics = 10, n_top_words = 20, seed = 0):\n",
        "    \"\"\"\n",
        "    Perform topic modeling on the movie review corpus and return the most frequent words in each topic.\n",
        "\n",
        "    args:\n",
        "        reviews (pd.Series[str]) : a Series of all processed movie reviews\n",
        "\n",
        "    kwargs:\n",
        "        n_topics (int) : the number of topics to model by LDA\n",
        "        n_top_words (int) : the number of most frequent words to identify in each topic\n",
        "        seed (int) : the random generator seed for LDA\n",
        "\n",
        "    return:\n",
        "        List[List[str]] : a nested list of words, where each of the n_topics inner lists\n",
        "            contains the n_top_words most frequent words in a given topic\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Use the existing count_vectorizer function from Q11 to get term-frequency matrix and feature names\n",
        "    tf_matrix, _, feature_names = count_vectorizer(reviews)\n",
        "\n",
        "    # Step 2: Apply Latent Dirichlet Allocation (LDA)\n",
        "    lda = LatentDirichletAllocation(\n",
        "        n_components=n_topics,\n",
        "        random_state=seed,\n",
        "        learning_method=\"online\"\n",
        "    )\n",
        "\n",
        "    lda.fit(tf_matrix)\n",
        "\n",
        "    # Step 3: Get the most frequent words for each topic **without reversing the order**\n",
        "    topic_words = []\n",
        "    for topic_idx, topic in enumerate(lda.components_):\n",
        "        top_indices = topic.argsort()[-n_top_words:]  # Get top word indices\n",
        "        top_words = [feature_names[i] for i in top_indices]  # Extract words in correct order\n",
        "        topic_words.append(top_words)  # Store topic words\n",
        "\n",
        "    return topic_words\n"
      ],
      "metadata": {
        "id": "wFfZLm4K0tz6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [
          "excluded_from_script"
        ],
        "id": "hboHYJnbMoha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1873e722-8b1d-437c-dc83-c814f60572ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ],
      "source": [
        "def test_top_words_by_topic():\n",
        "    corpus = pd.Series([\n",
        "        \"I like to eat broccoli and bananas\",\n",
        "        \"I ate a banana and spinach smoothie for breakfast\",\n",
        "        \"Chinchillas and kittens are cute\",\n",
        "        \"My sister adopted a kitten yesterday\",\n",
        "        \"Look at this cute hamster munching on a piece of broccoli\"\n",
        "    ])\n",
        "    top_words = top_words_by_topic(corpus, n_topics = 2, n_top_words = 5)\n",
        "    # print(top_words)\n",
        "    assert top_words == [['Look', 'broccoli', 'and', 'cute', 'a'], ['I', 'eat', 'like', 'to', 'and']]\n",
        "\n",
        "    top_words = top_words_by_topic(df_reviews[\"processed_review\"], n_topics = 5, n_top_words = 5)\n",
        "    assert top_words == [\n",
        "        ['performance', 'play', 'version', 'jack', 'role'],\n",
        "        ['dancer', 'paris', 'dance', 'cartoon', 'hitchcock'],\n",
        "        ['make', 'like', 'one', 'film', 'movie'],\n",
        "        ['film', 'father', 'world', 'american', 'war'],\n",
        "        ['mad', 'sheriff', 'match', 'carmen', 'arthur']\n",
        "    ]\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "test_top_words_by_topic()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWkJiswSMoha"
      },
      "source": [
        "### Bonus: Word embedding and word similarity\n",
        "Finally, let's look at how we can train a word embedding model from our movie review corpus. Unfortunately, gensim's `Word2Vec` does not output reproducible results across different environments, so we will not grade this question. Instead, here we provide the implementation of the function `get_most_similar_words` that takes as input the `processed_reviews` column in our IMDB dataset, and for each input word, returns a list of `n_similar_words` top similar tokens to that word, based on the Word2Vec model. Here the tokens are ordered from lower to higher similarity values.\n",
        "\n",
        "You can see the code below and play around with different settings to better understand Word2Vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5w0KsNoMoha"
      },
      "outputs": [],
      "source": [
        "def find_most_similar_words(reviews, input_words, n_similar_words):\n",
        "    corpus = [review.split() for review in reviews]\n",
        "    model = Word2Vec(sentences = corpus, vector_size = 100, window = 5, workers = 4, min_count = 1)\n",
        "    similar_words = []\n",
        "    for inp_word in input_words:\n",
        "        similar_words.append([w for w in sorted(model.wv.most_similar(inp_word, topn = n_similar_words), key = lambda x: x[1])])\n",
        "    return similar_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "excluded_from_script"
        ],
        "id": "WKiQFRR9Moha"
      },
      "outputs": [],
      "source": [
        "def test_find_most_similar_words():\n",
        "    input_words = [\"see\", \"good\", \"bad\", \"watch\", \"check\"]\n",
        "    most_similar_words = find_most_similar_words(df_reviews[\"processed_review\"], input_words, 7)\n",
        "    for i in range(len(input_words)):\n",
        "        print(f\"Words most similar to '{input_words[i]}':\")\n",
        "        print(most_similar_words[i])\n",
        "        print()\n",
        "\n",
        "test_find_most_similar_words()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "def find_most_similar_words(reviews, input_words, n_similar_words):\n",
        "    \"\"\"\n",
        "    Train a Word2Vec model on the review corpus and find the most similar words for each input word.\n",
        "\n",
        "    args:\n",
        "        reviews (pd.Series[str]) : a Series of processed movie reviews\n",
        "        input_words (List[str]) : a list of input words for which similar words are to be found\n",
        "        n_similar_words (int) : number of top similar words to return for each input word\n",
        "\n",
        "    return:\n",
        "        List[List[Tuple[str, float]]] : a nested list where each inner list contains tuples of\n",
        "                                       (word, similarity score) for the n_similar_words most\n",
        "                                       similar words to each input word\n",
        "    \"\"\"\n",
        "    # Prepare the corpus by splitting each review into a list of words\n",
        "    corpus = [review.split() for review in reviews]\n",
        "\n",
        "    # Train the Word2Vec model\n",
        "    model = Word2Vec(\n",
        "        sentences=corpus,\n",
        "        vector_size=100,  # Dimensionality of word vectors\n",
        "        window=5,         # Context window size\n",
        "        workers=4,        # Number of worker threads for training\n",
        "        min_count=1       # Minimum frequency count of words\n",
        "    )\n",
        "\n",
        "    similar_words = []\n",
        "\n",
        "    for inp_word in input_words:\n",
        "        if inp_word in model.wv:\n",
        "            # Retrieve and sort similar words by similarity score (ascending order)\n",
        "            similar = sorted(\n",
        "                model.wv.most_similar(inp_word, topn=n_similar_words),\n",
        "                key=lambda x: x[1]\n",
        "            )\n",
        "        else:\n",
        "            similar = []  # If the word is not in the vocabulary\n",
        "        similar_words.append(similar)\n",
        "\n",
        "    return similar_words\n"
      ],
      "metadata": {
        "id": "N75rQmwlgPZ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}